---
title: "MovieLens project"
author: "XuMan"
date: "2020/5/3"
output: 
  html_document:
    toc : TRUE
    number_sections: true
---



``` {r include = FALSE}
library("tidyverse")
library("caret")
library("data.table")
library("knitr")
```

# Executive summary

Recommendation systems aim to make specific recommendations to users in order to promote sales or exposure. Recommendation systems can greatly facilitate the browsing activities of users and are widely used by e-commerce websites, social platforms and content providers. They are more important these days since online platforms are providing larger varieties of products or other items, such as movies, user-generated pictures and messages. 

For this project, we will focus on a movie recommendation system. Online streaming media platforms, such as Netflix, provide many movies to many users. They encourage users to provide ratings on the movies they have watched. The general idea behind the movie recommendation system is to predict the users' ratings on the movies and movies with high predicted ratings are likely to be favored more than movies with low predicted ratings.

## Goal of the project

The aim of the project is to create a machine learning algorithm that predicts the rating for a movie *i* by user *u*:
$$\hat{y}_{u,i}$$ . 

Performance of the algorithm is evaluated by residual mean squared error (RMSE) on the test set, which is defined as:
$$ RMSE = \sqrt{\frac{1}{N}\displaystyle\sum_{u,i} (\hat{y}_{u,i}-y_{u,i})^{2}} $$

with N being the total number of user/movie combinations in the test set.

RMSE can be interpreted as the typical error the algorithm make when predicting a movie rating. For example, if RMSE is 1, it means the prediction of then algorithm is typically 1 star away from the real value.

Based on previous research and guidance on the project, a RMSE less than 0.86490 would be assumed a good prediction.

```{r define RMSE function echo=FALSE}
RMSE <- function(true_ratings, predicted_ratings){
  sqrt(mean((true_ratings - predicted_ratings)^2))
  }
```

## Dataset description

Dataset used in this report is a subset of the MovieLens dataset generated by the GroupLens research lab. The dataset is further divided into an edx set, which is used to develop the algorithm and a validation set, which is for the final test of the algorithm. 

```{r include=FALSE, cache=TRUE}
################################
# Create edx set, validation set
################################

# Note: this process could take a couple of minutes

if(!require(tidyverse)) install.packages("tidyverse", repos = "http://cran.us.r-project.org")
if(!require(caret)) install.packages("caret", repos = "http://cran.us.r-project.org")
if(!require(data.table)) install.packages("data.table", repos = "http://cran.us.r-project.org")

# MovieLens 10M dataset:
 # https://grouplens.org/datasets/movielens/10m/
 # http://files.grouplens.org/datasets/movielens/ml-10m.zip

dl <- tempfile()
 download.file("http://files.grouplens.org/datasets/movielens/ml-10m.zip", dl)

ratings <- fread(text = gsub("::", "\t", readLines(unzip(dl, "ml-10M100K/ratings.dat"))),
                 col.names = c("userId", "movieId", "rating", "timestamp"))

movies <- str_split_fixed(readLines(unzip(dl, "ml-10M100K/movies.dat")), "\\::", 3)
 colnames(movies) <- c("movieId", "title", "genres")
 movies <- as.data.frame(movies) %>% mutate(movieId = as.numeric(levels(movieId))[movieId],
                                            title = as.character(title),
                                            genres = as.character(genres))

movielens <- left_join(ratings, movies, by = "movieId")

# Validation set will be 10% of MovieLens data
set.seed(1, sample.kind="Rounding")
# if using R 3.5 or earlier, use `set.seed(1)` instead
test_index <- createDataPartition(y = movielens$rating, times = 1, p = 0.1, list = FALSE)
 edx <- movielens[-test_index,]
 temp <- movielens[test_index,]

# Make sure userId and movieId in validation set are also in edx set
validation <- temp %>% 
      semi_join(edx, by = "movieId") %>%
      semi_join(edx, by = "userId")

# Add rows removed from validation set back into edx set
removed <- anti_join(temp, validation)
 edx <- rbind(edx, removed)

rm(dl, ratings, movies, test_index, temp, movielens, removed)
```

Next we are going to take a closer look ar the edx dataset. The validation dataset is of similar structure with the edx dataset but of smaller size.

* Table structure
The edx dataset is in tidy form with `r nrow(edx)` rows and the first 6 rows are as follows:

```{r echo=FALSE}
knitr::kable(head(edx))
```

We can see that the table contains six variebles:“userId”, “movieId”, “rating”, “timestamp”, “title”, and “genres”. Each row represents a rating given by one user to one movie in the table. The variebles "userId" and "movieId" provide unique ID numbers for each user and each movie. The varieble "rating" shows rating of the movie marked by the user. The varieble "timestamp" represents the time and data in which the rating was provided with units being seconds since January 1, 1970. The varieble "title" provides the movie title and also the year in which the movie was released. The varieble "genres" includes every genre that applies to the movie and some movies fall under several genres.

There are `r n_distinct(edx$movieId)` unique movies and `r n_distinct(edx$userId)` unique users in the dataset. Not every user rated every movie. The average number of movies rated by an user is `r round(nrow(edx)/n_distinct(edx$userId))`. The average number of ratings a movies received is `r round(nrow(edx)/n_distinct(edx$movieId))`

* Rating distribution

If we take a look at the distribution of ratings, we can find that users tend to give higher ratings and the most frequent rating is 4, followed by 3 and 5. In general, wholestar ratings are more common than half star ratings. The average rating given by users is `r mean(edx$rating)`.

``` {r echo = FALSE, warning = FALSE}
edx %>% ggplot(aes(rating)) +
  geom_histogram() +
  ggtitle("Rating Distribution") +
  xlab("Rating")+
  scale_x_continuous(breaks = c(seq(0.5,5,0.5))) +
  scale_y_continuous(breaks = c(seq(0, 3000000, 500000)))
```

* Distribution of average rating by movies

The graphic shows that Movies are rated very differently. Therefore we can take into account the effect of movies in our model.

```{r plot-distribution-of-movie-average-rating, echo=FALSE, warning=FALSE}
edx %>% group_by(movieId) %>% 
  summarize(movie_avgs = mean(rating)) %>%
  ggplot(aes(movie_avgs)) +
  geom_histogram(color = "white") +
  ggtitle("Distribution of average rating by movies") +
  xlab("Average rating") +
  ylab("Number of movies")
```

* Distribution of average rating by users

Users also give different average ratings so user effect needs to be included into our model as well.

```{r plot-distribution-of-user-average-rating, echo=FALSE, warning=FALSE}
edx %>% group_by(userId) %>% 
  summarize(user_avgs = mean(rating)) %>%
  ggplot(aes(user_avgs)) +
  geom_histogram(color = "white") +
  ggtitle("Distribution of average rating by users") +
  xlab("Average rating") +
  ylab("Number of users")
```

* Distribution of number of ratings per movie

We can see that the number of ratings of movies are quite different. In fact, there are `r edx %>% group_by(movieId) %>% summarize(number_of_rating_per_movie = n()) %>% filter(number_of_rating_per_movie == 1) %>% nrow()` movies that are only rated once. So when we try to quantify movie effect, movies with few ratings have more uncertainty because of the lack of a large enough sample size and larger estimates of movies effect are more likely, which can lead to the increase in RMSE. Therefore, we need to perform regularization and penalize large estimates that are formed using small sample sizes.

```{r echo = FALSE}
edx %>% group_by(movieId) %>%
  summarize(number_of_rating_per_movie = n()) %>%
  ggplot(aes(number_of_rating_per_movie)) +
  geom_histogram(color = "white") +
  ggtitle("Distribution of number of ratings per movie") +
  xlab("Number of ratings") +
  ylab("Number of movies") +
  scale_x_log10()
```

* Distribution of number of ratings per user

The number of ratings generated by users also varies greatly from person to person. There are `r edx %>% group_by(userId) %>% summarize(number_of_rating_per_user = n()) %>% filter(number_of_rating_per_user < 20) %>% nrow()` users who are less active and gives less than 20 ratings, while there are `r edx %>% group_by(userId) %>% summarize(number_of_rating_per_user = n()) %>% filter(number_of_rating_per_user > 2000) %>% nrow()` users who are much more active and gives more than 20 ratings. Penalty for small number of ratings per user will also be introduced in our model.

``` {r echo=FALSE, warning=FALSE}
edx %>% group_by(userId) %>%
  summarize(number_of_rating_per_user = n()) %>%
  ggplot(aes(number_of_rating_per_user)) +
  geom_histogram(color = "white") +
  ggtitle("Distribution of number of ratings per user") +
  xlab("Number of ratings") +
  ylab("Number of users") +
  scale_x_log10()
```

## Key methods

**To be finished**

# Analysis

## Create train and test set

We further divide the edx set into train set (80%) and test set (20%), so that the test set can be used to compare the performance of different models.

``` {r train-test-partition incude=FALSE}
set.seed(2029)
test_index <- createDataPartition(y = edx$rating, times = 1, p = 0.2, list = FALSE)
train_set <- edx[-test_index,]
test_set <- edx[test_index,]
test_set <- test_set %>% 
  semi_join(train_set, by = "movieId") %>%
  semi_join(train_set, by = "userId")
```

## Regularized movie and user effect model

Our model that takes into account movie and user effect is: 
$$ Y_{u, i} = \mu + b_i + b_u + \epsilon_{u, i} $$

To constrain the total variability of the effect sizes, we introduce regularization. Instead of defining $\hat{b}_u$ as the average of $Y_{u, i} - \hat{\mu}$, we use:
$$ \hat{b}_i(\lambda) = \frac{1}{\lambda + n_i}\displaystyle\sum_{u = 1}^{n_i}(Y_{u, i} - \hat{\mu}) $$

Similarly, we define:
$$ \hat{b}_{u, i}(\lambda) = \frac{1}{\lambda + n_u}\displaystyle\sum_{u = 1}^{n_u}(Y_{u, i} - \hat{\mu} - \hat{b}_i)$$

```{r movie-and-user-effect-model, include=FALSE}
lambdas_iu_1 <- seq(0, 10, 1)
rmse_iu_1 <- sapply(lambdas_iu_1, function(lambda){
  b_i <- train_set %>% 
    group_by(movieId) %>% 
    summarize(b_i = sum(rating - mu)/(n()+lambda)) 
  
  b_u <- train_set %>% 
    left_join(b_i, by='movieId') %>%
    group_by(userId) %>%
    summarize(b_u = sum(rating - mu - b_i)/(n()+lambda))
  
  predicted_ratings <- test_set %>% 
    left_join(b_i, by = "movieId") %>%
    left_join(b_u, by = "userId") %>%
    mutate(pred = mu + b_i + b_u) %>%
    pull(pred)
  
  RMSE(predicted_ratings, test_set$rating)
})
plot(lambdas_iu_1, rmse_iu_1)

lambdas_iu_2 <- seq(4, 6, 0.1)
rmse_iu_2 <- sapply(lambdas_iu_2, function(lambda){
  b_i <- train_set %>% 
    group_by(movieId) %>% 
    summarize(b_i = sum(rating - mu)/(n()+lambda)) 
  
  b_u <- train_set %>% 
    left_join(b_i, by='movieId') %>%
    group_by(userId) %>%
    summarize(b_u = sum(rating - mu - b_i)/(n()+lambda))
  
  predicted_ratings <- test_set %>% 
    left_join(b_i, by = "movieId") %>%
    left_join(b_u, by = "userId") %>%
    mutate(pred = mu + b_i + b_u) %>%
    pull(pred)
  
  RMSE(predicted_ratings, test_set$rating)
})
```

By cross validation, we tested $\lambda$ in the range of 1 and 10 with 0.1 intervals and pick the $\lambda$ that gives the lowest RMSE for this model. The RMSE is `{r} rmse_iu_2[which.min(rmse_iu_2)]`, with the optimal $\lambda$ being `{r} lambdas_iu_2[which.min(rmse_iu_2)]`

# Results

Based on the analysis above, we are able to generate a regularized movie and user effect model:
$$ Y_{u, i} = \mu + b_i + b_u + \epsilon_{u, i} $$ 

``` {r include = FALSE}
b_i <- train_set %>% 
  group_by(movieId) %>% 
  summarize(b_i = sum(rating - mu)/(n()+lambda_iu)) 

b_u <- train_set %>% 
  left_join(b_i, by='movieId') %>%
  group_by(userId) %>%
  summarize(b_u = sum(rating - mu - b_i)/(n()+lambda_iu))

predicted_ratings_on_validationset <- validation %>% 
  left_join(b_i, by = "movieId") %>%
  left_join(b_u, by = "userId") %>%
  mutate(pred = mu + b_i + b_u) %>%
  pull(pred)

RMSE <- RMSE(predicted_ratings_on_validationset, validation$rating)
```

The RMSE on validation set is `r RMSE`.

# Conclusion


a brief summary of the report, its limitations and future work






